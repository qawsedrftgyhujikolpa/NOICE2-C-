using OpenCvSharp;
using Microsoft.Extensions.Logging;
using System.Linq;
using System.Threading.Tasks;
using System.Collections.Generic;

namespace NoiceServer;

/// <summary>
/// å‹•ç”»ã‹ã‚‰èƒŒæ™¯ã‚’æ¶ˆå»ã—ã€å‹•ãã‚’ãƒã‚¤ã‚ºã§å¯è¦–åŒ–ã™ã‚‹å‡¦ç†
/// â”€â”€ æ¥µé™çˆ†é€ŸåŒ–ç‰ˆ â”€â”€
/// </summary>
public static class NoiceProcessor
{
    // ãƒã‚¤ã‚ºãƒ—ãƒ¼ãƒ«æšæ•°: 500â†’30 ã«å¤§å¹…å‰Šæ¸›ã€‚è¦‹ãŸç›®ã«ã¯ã»ã¼å·®ãªã—ã€èµ·å‹•ãŒçˆ†é€Ÿã«ãªã‚‹ã€‚
    private const int NoisePoolSize = 30;

    // MOG2 ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆé€šå¸¸ãƒ¢ãƒ¼ãƒ‰ç”¨ï¼‰
    private const int Mog2History = 300;
    private const int Mog2VarThreshold = 60;

    // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ™‚ã® JPEG å“è³ªã€‚95(ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)â†’70 ã«è½ã¨ã—ã¦ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰é€Ÿåº¦ã¨è»¢é€é€Ÿåº¦ã‚’ç¨¼ãã€‚
    private static readonly int[] JpegStreamParams = { (int)ImwriteFlags.JpegQuality, 70 };
    // ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã¯å°‘ã—å“è³ªã‚’ä¸Šã’ã‚‹ï¼ˆã©ã†ã›å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹ãŒï¼‰ã€‚
    private static readonly int[] JpegSaveParams = { (int)ImwriteFlags.JpegQuality, 85 };

    /// <summary>
    /// ãƒã‚¤ã‚ºãƒ—ãƒ¼ãƒ«ç”Ÿæˆï¼ˆä¸¦åˆ—+ãƒ–ãƒ©ãƒ¼å»ƒæ­¢ã§çˆ†é€Ÿï¼‰
    /// 30æšã‚ã‚Œã°ååˆ†ã€‚ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚ºã«ãƒ–ãƒ©ãƒ¼ã‹ã‘ã¦ã‚‚èª°ã‚‚æ°—ã¥ã‹ãªã„ã‹ã‚‰å»ƒæ­¢ã€‚
    /// </summary>
    public static Mat[] CreateNoisePool(int w, int h, bool isColor, ILogger? log = null)
    {
        log?.LogInformation("ğŸŒ€ ãƒã‚¤ã‚ºãƒ—ãƒ¼ãƒ«ç”Ÿæˆ: {Size}æš ({W}x{H})", NoisePoolSize, w, h);
        var pool = new Mat[NoisePoolSize];

        // å…¨ã‚³ã‚¢ã§ä¸¦åˆ—ç”Ÿæˆ
        Parallel.For(0, NoisePoolSize, i =>
        {
            if (isColor)
            {
                var noise = new Mat(h, w, MatType.CV_8UC3);
                Cv2.Randu(noise, new Scalar(0, 0, 0), new Scalar(256, 256, 256));
                // GaussianBlur ã¯å»ƒæ­¢ã€‚ãƒã‚¤ã‚ºã«ãƒ–ãƒ©ãƒ¼ã‚’ã‹ã‘ã¦ã‚‚è¦‹ãŸç›®å¤‰ã‚ã‚‰ã‚“ã€‚
                pool[i] = noise;
            }
            else
            {
                var gray = new Mat(h, w, MatType.CV_8UC1);
                Cv2.Randu(gray, new Scalar(0), new Scalar(256));
                var noise = new Mat();
                Cv2.CvtColor(gray, noise, ColorConversionCodes.GRAY2BGR);
                gray.Dispose();
                pool[i] = noise;
            }
        });

        log?.LogInformation("âœ… Poolç”Ÿæˆå®Œäº†");
        return pool;
    }

    /// <summary>
    /// 1ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ï¼ˆæ¥µé™æœ€é©åŒ–ç‰ˆï¼‰
    /// mask ã¨ maskDilate ã¯ãƒãƒƒãƒ•ã‚¡ã¨ã—ã¦å¤–ã‹ã‚‰æ¸¡ã—ã¦ã‚‚ã‚‰ã„ã€æ¯ãƒ•ãƒ¬ãƒ¼ãƒ  new ã—ãªã„ã€‚
    /// </summary>
    public static void ProcessFrame(
        Mat frame,
        Mat[] pool,
        Mat staticNoise,
        object? detector,
        int poolIndex,
        Mat result,       // å‡ºåŠ›ãƒãƒƒãƒ•ã‚¡ï¼ˆå¤–éƒ¨ã§ç¢ºä¿æ¸ˆã¿ï¼‰
        Mat mask,         // ãƒã‚¹ã‚¯ãƒãƒƒãƒ•ã‚¡ï¼ˆå¤–éƒ¨ã§ç¢ºä¿æ¸ˆã¿ï¼‰
        Mat maskDilate,   // è†¨å¼µãƒã‚¹ã‚¯ãƒãƒƒãƒ•ã‚¡ï¼ˆå¤–éƒ¨ã§ç¢ºä¿æ¸ˆã¿ï¼‰
        bool nitroMode,
        Mat? prevGray,
        Mat? grayBuf)     // ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›ç”¨ãƒãƒƒãƒ•ã‚¡
    {
        bool hasMask = false;

        if (nitroMode && prevGray != null && grayBuf != null)
        {
            // --- Nitro Mode: ãƒ•ãƒ¬ãƒ¼ãƒ é–“å·®åˆ†ï¼ˆæœ€é€Ÿï¼‰ ---
            Cv2.CvtColor(frame, grayBuf, ColorConversionCodes.BGR2GRAY);
            Cv2.Absdiff(grayBuf, prevGray, mask);
            Cv2.Threshold(mask, mask, 25, 255, ThresholdTypes.Binary);
            grayBuf.CopyTo(prevGray);
            hasMask = true;
        }
        else if (detector is BackgroundSubtractorMOG2 backSub)
        {
            // --- Normal Mode: èƒŒæ™¯å·®åˆ†æ³• ---
            // ãƒ–ãƒ©ãƒ¼ã®ã‚«ãƒ¼ãƒãƒ«ã‚’ 9â†’5 ã«ã•ã‚‰ã«å°ã•ãã€‚ç²¾åº¦ã¯å°‘ã—è½ã¡ã‚‹ãŒé€Ÿåº¦å„ªå…ˆã€‚
            Cv2.GaussianBlur(frame, mask, new OpenCvSharp.Size(5, 5), 0);
            backSub.Apply(mask, mask);
            hasMask = true;
        }

        // ãƒã‚¤ã‚ºåˆæˆ
        staticNoise.CopyTo(result);
        if (hasMask)
        {
            // Nitroæ™‚ã¯è†¨å¼µï¼ˆDilateï¼‰ã‚‚ã‚¹ã‚­ãƒƒãƒ—å¯ã€‚è¦‹ãŸç›®ã‚ˆã‚Šã‚¹ãƒ”ãƒ¼ãƒ‰å„ªå…ˆã€‚
            if (nitroMode)
            {
                // Dilate ãªã—ã§ç›´æ¥åˆæˆ â†’ ã•ã‚‰ã«é«˜é€Ÿ
                pool[poolIndex % NoisePoolSize].CopyTo(result, mask);
            }
            else
            {
                using var kernel = Cv2.GetStructuringElement(MorphShapes.Rect, new OpenCvSharp.Size(3, 3));
                Cv2.Dilate(mask, maskDilate, kernel, iterations: 1);
                pool[poolIndex % NoisePoolSize].CopyTo(result, maskDilate);
            }
        }
    }

    /// <summary>
    /// ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨ï¼ˆæ¥µé™çˆ†é€Ÿç‰ˆï¼‰
    /// ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ— + ä½å“è³ªJPEGã§å¸¯åŸŸã¨å‡¦ç†æ™‚é–“ã‚’å¤§å¹…ã‚«ãƒƒãƒˆã€‚
    /// </summary>
    public static async IAsyncEnumerable<byte[]> ProcessVoidStreamAsync(
        string tempPath,
        double scale,
        bool isColor,
        double speed,
        bool nitroMode,
        ILogger? log,
        [System.Runtime.CompilerServices.EnumeratorCancellation] CancellationToken cancellationToken = default)
    {
        using var cap = new VideoCapture(tempPath);
        if (!cap.IsOpened()) yield break;

        double fps = cap.Get(VideoCaptureProperties.Fps);
        if (fps <= 0) fps = 30.0;
        int w = (int)(cap.Get(VideoCaptureProperties.FrameWidth) * scale);
        int h = (int)(cap.Get(VideoCaptureProperties.FrameHeight) * scale);

        // speed > 1 ã®å ´åˆã€ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é£›ã°ã—ã¦ç‰©ç†çš„ãªå‡¦ç†é‡ã‚’æ¸›ã‚‰ã™
        // ä¾‹: speed=2.0 â†’ 1ãƒ•ãƒ¬ãƒ¼ãƒ ãŠãã«ã‚¹ã‚­ãƒƒãƒ—
        int skipEvery = speed > 1.0 ? (int)Math.Round(speed) : 1;

        var pool = CreateNoisePool(w, h, isColor, log);
        try
        {
            using var staticNoise = pool[0].Clone();
            using var backSub = nitroMode ? null : BackgroundSubtractorMOG2.Create(Mog2History, Mog2VarThreshold, false);
            using var prevGray = nitroMode ? new Mat(h, w, MatType.CV_8UC1, new Scalar(0)) : null;
            using var grayBuf = nitroMode ? new Mat() : null;

            double frameDelay = 1.0 / (fps * speed);
            int pIdx = 0;
            int frameCount = 0;
            var sw = System.Diagnostics.Stopwatch.StartNew();

            // å…¨ãƒãƒƒãƒ•ã‚¡ã‚’å¤–ã§ç¢ºä¿ã—ã¦ä½¿ã„å›ã™ï¼ˆGCã‚’æ¥µé™ã¾ã§æ¸›ã‚‰ã™ï¼‰
            using var frame = new Mat();
            using var resized = new Mat();
            using var result = new Mat();
            using var mask = new Mat();
            using var maskDilate = new Mat();

            while (cap.Read(frame) && !frame.Empty() && !cancellationToken.IsCancellationRequested)
            {
                frameCount++;

                // ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—: speed > 1 ãªã‚‰é–“å¼•ã
                if (skipEvery > 1 && (frameCount % skipEvery) != 0)
                    continue;

                sw.Restart();

                // Nearest è£œé–“ = æœ€é€Ÿã®ãƒªã‚µã‚¤ã‚ºæ–¹å¼
                Cv2.Resize(frame, resized, new OpenCvSharp.Size(w, h), 0, 0, InterpolationFlags.Nearest);

                ProcessFrame(resized, pool, staticNoise, (object?)backSub ?? prevGray!, pIdx, result, mask, maskDilate, nitroMode, prevGray, grayBuf);

                // JPEGå“è³ª70ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã ã—è¨±ã›ï¼‰
                Cv2.ImEncode(".jpg", result, out byte[] jpegBytes, JpegStreamParams);
                yield return jpegBytes;

                pIdx++;

                double wait = frameDelay - sw.Elapsed.TotalSeconds;
                if (wait > 0)
                    await Task.Delay(TimeSpan.FromSeconds(wait), cancellationToken).ConfigureAwait(false);
            }
        }
        finally
        {
            foreach (var m in pool) m.Dispose();
        }
    }

    /// <summary>
    /// ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ï¼ˆæ¥µé™çˆ†é€Ÿç‰ˆï¼‰
    /// </summary>
    public static void SaveProcessedVideo(string tempPath, string outputPath, double scale, bool isColor, string audioMode, bool nitroMode, ILogger log, Action<double>? onProgress = null)
    {
        using var cap = new VideoCapture(tempPath);
        if (!cap.IsOpened()) throw new InvalidOperationException("Failed to open video");

        double fps = cap.Get(VideoCaptureProperties.Fps);
        if (fps <= 0) fps = 30.0;
        int w = (int)(cap.Get(VideoCaptureProperties.FrameWidth) * scale);
        int h = (int)(cap.Get(VideoCaptureProperties.FrameHeight) * scale);
        int totalFrames = (int)cap.Get(VideoCaptureProperties.FrameCount);

        string tempSilent = outputPath + ".silent.mp4";
        var pool = CreateNoisePool(w, h, isColor, log);
        try
        {
            using var writer = new VideoWriter(tempSilent, FourCC.MP4V, fps, new OpenCvSharp.Size(w, h));
            using var staticNoise = pool[0].Clone();
            using var backSub = nitroMode ? null : BackgroundSubtractorMOG2.Create(Mog2History, Mog2VarThreshold, false);
            using var prevGray = nitroMode ? new Mat(h, w, MatType.CV_8UC1, new Scalar(0)) : null;
            using var grayBuf = nitroMode ? new Mat() : null;

            // å…¨ãƒãƒƒãƒ•ã‚¡å¤–éƒ¨ç¢ºä¿
            using var frame = new Mat();
            using var resized = new Mat();
            using var result = new Mat();
            using var mask = new Mat();
            using var maskDilate = new Mat();

            int pIdx = 0;
            while (cap.Read(frame) && !frame.Empty())
            {
                // ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¯å…¨ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ï¼ˆå“è³ªå„ªå…ˆï¼‰ã€ãŸã ã— Nearest ã§é€Ÿåº¦ç¨¼ã
                Cv2.Resize(frame, resized, new OpenCvSharp.Size(w, h), 0, 0, InterpolationFlags.Nearest);
                ProcessFrame(resized, pool, staticNoise, (object?)backSub ?? prevGray!, pIdx, result, mask, maskDilate, nitroMode, prevGray, grayBuf);

                writer.Write(result);
                pIdx++;
                if (pIdx % 30 == 0)
                {
                    double pct = (double)pIdx / totalFrames * 100;
                    log.LogInformation(" rendering... {PIdx}/{Total} ({Pct:F1}%)", pIdx, totalFrames, pct);
                    onProgress?.Invoke(pct);
                }
            }
            onProgress?.Invoke(100);
        }
        finally
        {
            foreach (var m in pool) m.Dispose();
        }

        cap.Release();

        // éŸ³å£°ãƒŸãƒƒã‚¯ã‚¹ï¼ˆFFmpegï¼‰
        try
        {
            MuxAudio(tempPath, tempSilent, outputPath, audioMode, fps, log);
        }
        catch (Exception ex)
        {
            log.LogError(ex, "Audio mixing failed");
            if (File.Exists(tempSilent) && !File.Exists(outputPath))
                File.Move(tempSilent, outputPath);
        }

        try { if (File.Exists(tempSilent)) File.Delete(tempSilent); } catch { }
        log.LogInformation("âœ¨ Rendering complete.");
    }

    private static void MuxAudio(string originalPath, string silentVideoPath, string outputPath, string audioMode, double fps, ILogger log)
    {
        static int RunFfmpeg(string args)
        {
            using var p = new System.Diagnostics.Process
            {
                StartInfo = new System.Diagnostics.ProcessStartInfo
                {
                    FileName = "ffmpeg",
                    Arguments = args,
                    UseShellExecute = false,
                    CreateNoWindow = true,
                    RedirectStandardError = true
                }
            };
            p.Start();
            p.StandardError.ReadToEnd();
            p.WaitForExit();
            return p.ExitCode;
        }

        if (audioMode == "mute")
        {
            if (RunFfmpeg($"-y -i \"{silentVideoPath}\" -c:v libx264 \"{outputPath}\"") != 0)
            {
                if (File.Exists(silentVideoPath))
                    File.Move(silentVideoPath, outputPath);
            }
            return;
        }

        if (audioMode == "original")
        {
            if (RunFfmpeg($"-y -i \"{silentVideoPath}\" -i \"{originalPath}\" -c:v libx264 -map 0:v -map 1:a? -c:a aac -shortest \"{outputPath}\"") != 0)
            {
                if (File.Exists(silentVideoPath))
                    File.Move(silentVideoPath, outputPath);
            }
            return;
        }

        if (audioMode is "white" or "brown")
        {
            double duration = 0;
            using (var pp = new System.Diagnostics.Process())
            {
                pp.StartInfo = new System.Diagnostics.ProcessStartInfo
                {
                    FileName = "ffprobe",
                    Arguments = $"-v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 \"{silentVideoPath}\"",
                    UseShellExecute = false,
                    RedirectStandardOutput = true,
                    CreateNoWindow = true
                };
                pp.Start();
                var outStr = pp.StandardOutput.ReadToEnd().Trim();
                pp.WaitForExit();
                double.TryParse(outStr, System.Globalization.NumberStyles.Any, System.Globalization.CultureInfo.InvariantCulture, out duration);
            }
            if (duration <= 0) duration = 60;
            string noiseType = audioMode == "white" ? "white" : "pink";
            string filter = $"-filter_complex \"[0:v]copy[v];[1:a]apad[a]\" -map \"[v]\" -map \"[a]\" -shortest -c:a aac";
            if (RunFfmpeg($"-y -i \"{silentVideoPath}\" -f lavfi -i anoisesrc=c={noiseType}:d={duration}:r=44100 {filter} \"{outputPath}\"") != 0)
            {
                if (File.Exists(silentVideoPath))
                    File.Move(silentVideoPath, outputPath);
            }
            return;
        }

        if (File.Exists(silentVideoPath))
            File.Move(silentVideoPath, outputPath);
    }
}
