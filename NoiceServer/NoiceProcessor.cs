using OpenCvSharp;
using Microsoft.Extensions.Logging;
using System.Linq;
using System.Threading.Tasks;
using System.Collections.Generic;

namespace NoiceServer;

/// <summary>
/// å‹•ç”»ã‹ã‚‰èƒŒæ™¯ã‚’æ¶ˆå»ã—ã€å‹•ãã‚’ãƒã‚¤ã‚ºã§å¯è¦–åŒ–ã™ã‚‹å‡¦ç†ï¼ˆPython server.py ã¨åŒç­‰ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
/// </summary>
public static class NoiceProcessor
{
    private const int NoisePoolSize = 500;
    private const int Mog2History = 300;
    private const int Mog2VarThreshold = 60;
    private const int BlurKernel = 15;
    private const int MedianKernel = 5;
    private const int DilateIterations = 2;

    /// <summary>
    /// é«˜å¯†åº¦ãƒã‚¤ã‚ºãƒ—ãƒ¼ãƒ«ã‚’ç”Ÿæˆï¼ˆä¸¦åˆ—å‡¦ç†ã§çˆ†é€ŸåŒ–ï¼‰
    /// </summary>
    public static List<Mat> CreateNoisePool(int w, int h, bool isColor, ILogger? log = null)
    {
        log?.LogInformation("ğŸŒ€ RAMæ¥µé™ã—ã°ããƒ¢ãƒ¼ãƒ‰: {Size}å€‹ã®å·¨å¤§ãƒã‚¤ã‚ºãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚’ç”Ÿæˆä¸­...", NoisePoolSize);
        var pool = new Mat[NoisePoolSize];
        
        // Parallel.For ã‚’ä½¿ã£ã¦ CPU ã®å…¨ã‚³ã‚¢ã§ãƒã‚¤ã‚ºã‚’ç”Ÿæˆã™ã‚‹ï¼ˆC#ã®æœ¬æ°—ï¼‰
        Parallel.For(0, NoisePoolSize, i =>
        {
            if (isColor)
            {
                var noise = new Mat(h, w, MatType.CV_8UC3);
                Cv2.Randu(noise, new Scalar(0, 0, 0), new Scalar(256, 256, 256));
                Cv2.GaussianBlur(noise, noise, new OpenCvSharp.Size(3, 3), 0);
                pool[i] = noise;
            }
            else
            {
                var gray = new Mat(h, w, MatType.CV_8UC1);
                Cv2.Randu(gray, new Scalar(0), new Scalar(256));
                var noise = new Mat();
                Cv2.CvtColor(gray, noise, ColorConversionCodes.GRAY2BGR);
                gray.Dispose();
                pool[i] = noise;
            }
        });

        log?.LogInformation("âœ… Pool generation complete.");
        return pool.ToList();
    }

    /// <summary>
    /// 1ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰
    /// </summary>
    public static void ProcessFrame(
        Mat frame, 
        List<Mat> pool, 
        Mat staticNoise, 
        object detector, // BackgroundSubtractorMOG2 ã¾ãŸã¯ å‰ã®ãƒ•ãƒ¬ãƒ¼ãƒ (Mat)
        int poolIndex, 
        Mat result,      // å‰ã‚‚ã£ã¦ç¢ºä¿ã•ã‚ŒãŸå‡ºåŠ›ç”¨ãƒãƒƒãƒ•ã‚¡
        bool nitroMode,
        Mat? prevGray = null)
    {
        using var mask = new Mat();
        
        if (nitroMode && prevGray != null)
        {
            // --- Nitro Mode: å˜ç´”ãªãƒ•ãƒ¬ãƒ¼ãƒ é–“å·®åˆ†ï¼ˆçˆ†é€Ÿï¼‰ ---
            using var gray = new Mat();
            Cv2.CvtColor(frame, gray, ColorConversionCodes.BGR2GRAY);
            Cv2.Absdiff(gray, prevGray, mask); // D ãŒå°æ–‡å­—ã®å¯èƒ½æ€§ãŒã‚ã‚‹
            Cv2.Threshold(mask, mask, 25, 255, ThresholdTypes.Binary);
            gray.CopyTo(prevGray); // æ¬¡ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãŸã‚ã«ä¿å­˜
        }
        else if (detector is BackgroundSubtractorMOG2 backSub)
        {
            // --- Normal Mode: èƒŒæ™¯å·®åˆ†æ³• (MOG2) ---
            using var blurred = new Mat();
            // ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚ºã‚’å°‘ã—å°ã•ãã—ã¦é«˜é€ŸåŒ–(15->9)
            Cv2.GaussianBlur(frame, blurred, new OpenCvSharp.Size(9, 9), 0);
            backSub.Apply(blurred, mask);
        }

        // ãƒã‚¤ã‚ºåˆæˆ
        staticNoise.CopyTo(result);
        if (!mask.Empty())
        {
            using var maskDilate = new Mat();
            Cv2.Dilate(mask, maskDilate, null, null, 1); // è†¨å¼µå‡¦ç†ã‚’1å›ã«æ¸›ã‚‰ã—ã¦é«˜é€ŸåŒ–
            var noiseFrame = pool[poolIndex % NoisePoolSize];
            noiseFrame.CopyTo(result, maskDilate);
        }
    }

    /// <summary>
    /// ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨: ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é †æ¬¡ yieldï¼ˆJPEG ãƒã‚¤ãƒˆ + MJPEG å¢ƒç•Œï¼‰
    /// </summary>
        public static async IAsyncEnumerable<byte[]> ProcessVoidStreamAsync(
        string tempPath,
        double scale,
        bool isColor,
        double speed,
        bool nitroMode, // è¿½åŠ 
        ILogger? log,
        [System.Runtime.CompilerServices.EnumeratorCancellation] CancellationToken cancellationToken = default)
    {
        using var cap = new VideoCapture(tempPath);
        if (!cap.IsOpened()) yield break;

        double fps = cap.Get(VideoCaptureProperties.Fps);
        if (fps <= 0) fps = 30.0;
        int w = (int)(cap.Get(VideoCaptureProperties.FrameWidth) * scale);
        int h = (int)(cap.Get(VideoCaptureProperties.FrameHeight) * scale);

        var pool = CreateNoisePool(w, h, isColor, log);
        try
        {
            using var staticNoise = pool[0].Clone();
            using var backSub = nitroMode ? null : BackgroundSubtractorMOG2.Create(Mog2History, Mog2VarThreshold, false);
            using var prevGray = nitroMode ? new Mat(h, w, MatType.CV_8UC1, new Scalar(0)) : null;

            double frameDelay = 1.0 / (fps * speed);
            int pIdx = 0;
            var sw = System.Diagnostics.Stopwatch.StartNew();

            using var frame = new Mat();
            using var resized = new Mat();
            using var result = new Mat(); // ãƒãƒƒãƒ•ã‚¡å†åˆ©ç”¨

            while (cap.Read(frame) && !frame.Empty() && !cancellationToken.IsCancellationRequested)
            {
                sw.Restart();
                Cv2.Resize(frame, resized, new OpenCvSharp.Size(w, h), 0, 0, InterpolationFlags.Area);
                
                ProcessFrame(resized, pool, staticNoise, (object?)backSub ?? prevGray!, pIdx, result, nitroMode, prevGray);
                
                Cv2.ImEncode(".jpg", result, out byte[] jpegBytes);
                yield return jpegBytes;
                
                pIdx++;

                double wait = frameDelay - sw.Elapsed.TotalSeconds;
                if (wait > 0)
                    await Task.Delay(TimeSpan.FromSeconds(wait), cancellationToken).ConfigureAwait(false);
            }
        }
        finally
        {
            foreach (var m in pool) m.Dispose();
        }
    }

    /// <summary>
    /// ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨: ç„¡éŸ³ MP4 ã‚’æ›¸ãå‡ºã—ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰
    /// </summary>
    public static void SaveProcessedVideo(string tempPath, string outputPath, double scale, bool isColor, string audioMode, bool nitroMode, ILogger log, Action<double>? onProgress = null)
    {
        using var cap = new VideoCapture(tempPath);
        if (!cap.IsOpened()) throw new InvalidOperationException("Failed to open video");

        double fps = cap.Get(VideoCaptureProperties.Fps);
        if (fps <= 0) fps = 30.0;
        int w = (int)(cap.Get(VideoCaptureProperties.FrameWidth) * scale);
        int h = (int)(cap.Get(VideoCaptureProperties.FrameHeight) * scale);
        int totalFrames = (int)cap.Get(VideoCaptureProperties.FrameCount);

        string tempSilent = outputPath + ".silent.mp4";
        var pool = CreateNoisePool(w, h, isColor, log);
        try
        {
            using var writer = new VideoWriter(tempSilent, FourCC.MP4V, fps, new OpenCvSharp.Size(w, h));
            using var staticNoise = pool[0].Clone();
            using var backSub = nitroMode ? null : BackgroundSubtractorMOG2.Create(Mog2History, Mog2VarThreshold, false);
            using var prevGray = nitroMode ? new Mat(h, w, MatType.CV_8UC1, new Scalar(0)) : null;
            
            using var frame = new Mat();
            using var resized = new Mat();
            using var result = new Mat();

            int pIdx = 0;
            while (cap.Read(frame) && !frame.Empty())
            {
                Cv2.Resize(frame, resized, new OpenCvSharp.Size(w, h), 0, 0, InterpolationFlags.Area);
                ProcessFrame(resized, pool, staticNoise, (object?)backSub ?? prevGray!, pIdx, result, nitroMode, prevGray);
                
                writer.Write(result);
                pIdx++;
                if (pIdx % 30 == 0)
                {
                    log.LogInformation(" rendering... {PIdx}/{Total}", pIdx, totalFrames);
                    onProgress?.Invoke((double)pIdx / totalFrames * 100);
                }
            }
            onProgress?.Invoke(100);
        }
        finally
        {
            foreach (var m in pool) m.Dispose();
        }

        cap.Release();

        // éŸ³å£°ãƒŸãƒƒã‚¯ã‚¹ï¼ˆFFMpegCoreï¼‰
        try
        {
            MuxAudio(tempPath, tempSilent, outputPath, audioMode, fps, log);
        }
        catch (Exception ex)
        {
            log.LogError(ex, "Audio mixing failed");
            if (File.Exists(tempSilent) && !File.Exists(outputPath))
                File.Move(tempSilent, outputPath);
        }

        try { if (File.Exists(tempSilent)) File.Delete(tempSilent); } catch { }
        log.LogInformation("âœ¨ Rendering complete.");
    }

    private static void MuxAudio(string originalPath, string silentVideoPath, string outputPath, string audioMode, double fps, ILogger log)
    {
        static int RunFfmpeg(string args)
        {
            using var p = new System.Diagnostics.Process
            {
                StartInfo = new System.Diagnostics.ProcessStartInfo
                {
                    FileName = "ffmpeg",
                    Arguments = args,
                    UseShellExecute = false,
                    CreateNoWindow = true,
                    RedirectStandardError = true
                }
            };
            p.Start();
            p.StandardError.ReadToEnd();
            p.WaitForExit();
            return p.ExitCode;
        }

        if (audioMode == "mute")
        {
            // ç„¡éŸ³å‹•ç”»ã‚’ libx264 ã§å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            if (RunFfmpeg($"-y -i \"{silentVideoPath}\" -c:v libx264 \"{outputPath}\"") != 0)
            {
                if (File.Exists(silentVideoPath))
                    File.Move(silentVideoPath, outputPath);
            }
            return;
        }

        if (audioMode == "original")
        {
            // å‹•ç”»1 + éŸ³å£°2 â†’ å‡ºåŠ›
            if (RunFfmpeg($"-y -i \"{silentVideoPath}\" -i \"{originalPath}\" -c:v libx264 -map 0:v -map 1:a? -c:a aac -shortest \"{outputPath}\"") != 0)
            {
                if (File.Exists(silentVideoPath))
                    File.Move(silentVideoPath, outputPath);
            }
            return;
        }

        if (audioMode is "white" or "brown")
        {
            // å‹•ç”»ã®é•·ã•ã‚’ ffprobe ã§å–å¾—
            double duration = 0;
            using (var pp = new System.Diagnostics.Process())
            {
                pp.StartInfo = new System.Diagnostics.ProcessStartInfo
                {
                    FileName = "ffprobe",
                    Arguments = $"-v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 \"{silentVideoPath}\"",
                    UseShellExecute = false,
                    RedirectStandardOutput = true,
                    CreateNoWindow = true
                };
                pp.Start();
                var outStr = pp.StandardOutput.ReadToEnd().Trim();
                pp.WaitForExit();
                double.TryParse(outStr, System.Globalization.NumberStyles.Any, System.Globalization.CultureInfo.InvariantCulture, out duration);
            }
            if (duration <= 0) duration = 60;
            string noiseType = audioMode == "white" ? "white" : "pink";
            string filter = $"-filter_complex \"[0:v]copy[v];[1:a]apad[a]\" -map \"[v]\" -map \"[a]\" -shortest -c:a aac";
            if (RunFfmpeg($"-y -i \"{silentVideoPath}\" -f lavfi -i anoisesrc=c={noiseType}:d={duration}:r=44100 {filter} \"{outputPath}\"") != 0)
            {
                if (File.Exists(silentVideoPath))
                    File.Move(silentVideoPath, outputPath);
            }
            return;
        }

        if (File.Exists(silentVideoPath))
            File.Move(silentVideoPath, outputPath);
    }
}
